{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1Tmqj1kgtOvPKLvnRcmgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomzkevin/kontempo/blob/main/Early_Warnings_Model_01_de_agosto_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-uRCLWU1jGS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "###############################################################################\n",
        "# CONFIG                                                                      #\n",
        "###############################################################################\n",
        "\n",
        "PAYMENTS_PATH = Path(\"payments.json\")  # update to real path or pass via CLI\n",
        "LIMITS_PATH = Path(\"Limit-Credit.csv\")  # update to real path or pass via CLI\n",
        "OUTPUT_PATH = Path(\"snapshots.parquet\")\n",
        "\n",
        "WINDOW_LOOKAHEAD_DAYS = 30   # how far after snapshot we collect due payments\n",
        "DPD_THRESHOLD = 35           # default definition: unpaid ≥ 35 days past due\n",
        "MATERIALITY = 0.96           # Amount Paid must reach 96% of Amount Due\n",
        "\n",
        "###############################################################################\n",
        "# RECEIPTS PARSER                                                             #\n",
        "###############################################################################\n",
        "\n",
        "def _clean_receipt_string(raw: str) -> str:\n",
        "    \"\"\"Remove EDN wrappers and return a simple token string.\"\"\"\n",
        "    return raw.replace(\"[#ordered/map\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "def parse_receipts(raw: str) -> List[Dict[str, Optional[pd.Timestamp]]]:\n",
        "    \"\"\"Parse the EDN-style *Receipts* column into a list of dicts.\n",
        "\n",
        "    Each dict contains:\n",
        "        - amount_applied: float\n",
        "        - applied_date: pandas.Timestamp | None\n",
        "    \"\"\"\n",
        "    if not raw or raw.strip() in {\"[]\", \"\"}:\n",
        "        return []\n",
        "\n",
        "    blocks = re.split(r\"#ordered/map\", raw)\n",
        "    receipts: List[Dict[str, Optional[pd.Timestamp]]] = []\n",
        "\n",
        "    for block in blocks:\n",
        "        if not block.strip():\n",
        "            continue\n",
        "        pairs = re.findall(r\"\\[:(\\w+)\\s+([^:\\]]+)\\]\", block)\n",
        "        data = {k: v for k, v in pairs}\n",
        "        try:\n",
        "            amt = float(str(data.get(\"amount_applied\", \"0\")).replace(\",\", \"\"))\n",
        "        except ValueError:\n",
        "            amt = 0.0\n",
        "        ts: Optional[pd.Timestamp]\n",
        "        if \"applied_date\" in data:\n",
        "            try:\n",
        "                ts = pd.to_datetime(int(str(data[\"applied_date\"]).replace(\",\", \"\")), unit=\"s\")\n",
        "            except ValueError:\n",
        "                ts = pd.NaT\n",
        "        else:\n",
        "            ts = pd.NaT\n",
        "        receipts.append({\"amount_applied\": amt, \"applied_date\": ts})\n",
        "    return receipts\n",
        "\n",
        "###############################################################################\n",
        "# DATA LOAD & CLEAN                                                           #\n",
        "###############################################################################\n",
        "\n",
        "def _clean_numeric(col: pd.Series) -> pd.Series:\n",
        "    return col.astype(str).str.replace(\",\", \"\", regex=False).astype(float)\n",
        "\n",
        "\n",
        "def load_payments(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_json(path, lines=False)\n",
        "    df = df[df[\"Status\"] != \"voided\"].copy()\n",
        "\n",
        "    # basic cleanup\n",
        "    df[\"Created_dt\"] = pd.to_datetime(df[\"Created\"].astype(str).str.replace(\",\", \"\", regex=False).astype(int), unit=\"s\")\n",
        "    df[\"Due_dt\"] = pd.to_datetime(df[\"Due Date\"])\n",
        "\n",
        "    numeric_cols = [\"Amount Due\", \"Amount Paid\", \"Principal Amount\"]\n",
        "    df[numeric_cols] = df[numeric_cols].apply(_clean_numeric)\n",
        "\n",
        "    df[\"quota_balance\"] = df[\"Amount Due\"] - df[\"Amount Paid\"]\n",
        "    df[\"is_unpaid\"] = df[\"Amount Paid\"] < MATERIALITY * df[\"Amount Due\"]\n",
        "\n",
        "    # Parse receipts into an auxiliary list column for faster downstream checks\n",
        "    df[\"_receipts\"] = df[\"Receipts\"].apply(parse_receipts)\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_limits(path: Path) -> pd.DataFrame:\n",
        "    limits = pd.read_csv(path)\n",
        "    limits = (\n",
        "        limits.groupby(\"Buyer Account ID\", as_index=False)[\"Limit\"].sum()\n",
        "            .rename(columns={\"Buyer Account ID\": \"Buyer Account\", \"Limit\": \"limite_de_credito\"})\n",
        "    )\n",
        "    return limits\n",
        "\n",
        "###############################################################################\n",
        "# FEATURE ENGINEERING                                                         #\n",
        "###############################################################################\n",
        "\n",
        "def _months_between(date1: pd.Timestamp, date2: pd.Timestamp) -> int:\n",
        "    return int((date2.to_period(\"M\") - date1.to_period(\"M\")).n)\n",
        "\n",
        "\n",
        "def build_snapshot_features(pay_hist: pd.DataFrame, snap_date: pd.Timestamp) -> pd.DataFrame:\n",
        "    \"\"\"Compute all features for a given snapshot.\"\"\"\n",
        "    gb = pay_hist.groupby(\"Buyer Account\")\n",
        "\n",
        "    feat = pd.DataFrame({\n",
        "        \"snapshot_date\": snap_date,\n",
        "        \"dias_desde_ultimo_prestamo\": (snap_date - gb[\"Created_dt\"].max()).dt.days,\n",
        "        \"acquisition_date\": gb[\"Created_dt\"].min(),\n",
        "        \"numero_total_prestamos_historico\": gb[\"Loan ID\"].nunique(),\n",
        "        \"saldo_pendiente_actual\": gb[\"quota_balance\"].sum(),\n",
        "        \"max_dpd_actual\": (\n",
        "            gb.apply(lambda g: ((snap_date - g.loc[g[\"is_unpaid\"], \"Due_dt\"]).dt.days).max() if (g[\"is_unpaid\"].any()) else 0))\n",
        "    })\n",
        "\n",
        "    # derive antiguedad & flags\n",
        "    feat[\"antiguedad_cliente_meses\"] = feat.apply(\n",
        "        lambda r: _months_between(r[\"acquisition_date\"], snap_date), axis=1\n",
        "    )\n",
        "    feat[\"es_primer_mes_activo\"] = (feat[\"antiguedad_cliente_meses\"] == 0).astype(int)\n",
        "\n",
        "    # last loan aggregates\n",
        "    last_loans = pay_hist.sort_values(\"Created_dt\").drop_duplicates(\"Buyer Account\", keep=\"last\")\n",
        "    feat = feat.join(last_loans.set_index(\"Buyer Account\")[[\"total_installments\", \"Principal Amount\"]].rename(\n",
        "        columns={\"total_installments\": \"installments_prestamo_reciente\", \"Principal Amount\": \"_last_principal\"}\n",
        "    ))\n",
        "\n",
        "    # historical averages\n",
        "    feat = feat.join(gb[\"total_installments\"].mean().rename(\"promedio_installments_historico\"))\n",
        "\n",
        "    # rolling windows\n",
        "    window_30 = pay_hist[pay_hist[\"Created_dt\"] >= snap_date - pd.Timedelta(days=30)]\n",
        "    gb30 = window_30.groupby(\"Buyer Account\")\n",
        "    feat = feat.join(gb30[\"Principal Amount\"].sum().rename(\"monto_dispuesto_ultimos_30d\"))\n",
        "    feat = feat.join(gb30[\"Loan ID\"].nunique().rename(\"frecuencia_prestamos_ultimos_30d\"))\n",
        "\n",
        "    window_31_60 = pay_hist[(pay_hist[\"Created_dt\"] >= snap_date - pd.Timedelta(days=60)) & (pay_hist[\"Created_dt\"] < snap_date - pd.Timedelta(days=30))]\n",
        "    gb60 = window_31_60.groupby(\"Buyer Account\")\n",
        "    feat = feat.join(gb60[\"Principal Amount\"].sum().rename(\"monto_dispuesto_31_60d\"))\n",
        "    feat = feat.join(gb60[\"Loan ID\"].nunique().rename(\"frecuencia_prestamos_31_60d\"))\n",
        "\n",
        "    # acceleration & deltas\n",
        "    feat[\"aceleracion_monto\"] = feat[\"monto_dispuesto_ultimos_30d\"].fillna(0) - feat[\"monto_dispuesto_31_60d\"].fillna(0)\n",
        "    feat[\"aceleracion_frecuencia\"] = feat[\"frecuencia_prestamos_ultimos_30d\"].fillna(0) - feat[\"frecuencia_prestamos_31_60d\"].fillna(0)\n",
        "    feat[\"cambio_en_installments_reciente\"] = feat[\"installments_prestamo_reciente\"] - feat[\"promedio_installments_historico\"]\n",
        "\n",
        "    return feat.reset_index()\n",
        "\n",
        "###############################################################################\n",
        "# LABEL GENERATION                                                            #\n",
        "###############################################################################\n",
        "\n",
        "def _payment_covered(row, due_date: pd.Timestamp) -> bool:\n",
        "    \"\"\"Return True if payment is covered ≥MATERIALITY within DPD_THRESHOLD.\"\"\"\n",
        "    deadline = due_date + timedelta(days=DPD_THRESHOLD)\n",
        "    paid = 0.0\n",
        "    for rec in row[\"_receipts\"]:\n",
        "        ts = rec.get(\"applied_date\")\n",
        "        if pd.isna(ts) or ts > deadline:\n",
        "            continue\n",
        "        paid += rec.get(\"amount_applied\", 0.0)\n",
        "    return paid >= MATERIALITY * row[\"Amount Due\"]\n",
        "\n",
        "\n",
        "def compute_label(pay_future: pd.DataFrame) -> pd.Series:\n",
        "    chk = pay_future.groupby(\"Buyer Account\").apply(\n",
        "        lambda g: not all(_payment_covered(r, r[\"Due_dt\"]) for _, r in g.iterrows())\n",
        "    )\n",
        "    return chk.astype(int)\n",
        "\n",
        "###############################################################################\n",
        "# MAIN BUILD FUNCTION                                                         #\n",
        "###############################################################################\n",
        "\n",
        "def build_snapshot_dataset(payments_path: Path = PAYMENTS_PATH,\n",
        "                           limits_path: Path = LIMITS_PATH,\n",
        "                           output_path: Path = OUTPUT_PATH) -> None:\n",
        "    pay = load_payments(payments_path)\n",
        "    limits = load_limits(limits_path)\n",
        "\n",
        "    # merge limits; placeholder imputation is deferred till after snapshots\n",
        "    pay = pay.merge(limits, how=\"left\", on=\"Buyer Account\")\n",
        "\n",
        "    snapshots = []\n",
        "    for snap in pd.date_range(pay[\"Due_dt\"].min().floor(\"M\"), pay[\"Due_dt\"].max().ceil(\"M\"), freq=\"M\"):\n",
        "        hist = pay[pay[\"Created_dt\"] <= snap]\n",
        "        feat = build_snapshot_features(hist, snap)\n",
        "\n",
        "        # add credit limit & utilisation (after imputation later)\n",
        "        feat = feat.join(limits.set_index(\"Buyer Account\"), on=\"Buyer Account\")\n",
        "        feat[\"limite_de_credito\"] = feat[\"limite_de_credito\"].fillna(feat[\"_last_principal\"])\n",
        "        feat[\"porcentaje_utilizacion\"] = feat[\"saldo_pendiente_actual\"] / feat[\"limite_de_credito\"]\n",
        "\n",
        "        # build label\n",
        "        future_mask = (pay[\"Due_dt\"] > snap) & (pay[\"Due_dt\"] <= snap + pd.Timedelta(days=WINDOW_LOOKAHEAD_DAYS))\n",
        "        pay_future = pay[future_mask]\n",
        "        labels = compute_label(pay_future)\n",
        "        feat[\"default_en_35d\"] = feat[\"Buyer Account\"].map(labels).fillna(0).astype(int)\n",
        "\n",
        "        # fossil filter\n",
        "        feat = feat[feat[\"max_dpd_actual\"] < 30]\n",
        "        snapshots.append(feat.drop(columns=[\"_last_principal\"]))\n",
        "\n",
        "    snapshots_df = pd.concat(snapshots).reset_index(drop=True)\n",
        "    snapshots_df.to_parquet(output_path, index=False)\n",
        "    print(f\"Snapshot dataset saved to {output_path} with {len(snapshots_df):,} rows.\")\n",
        "\n",
        "###############################################################################\n",
        "# CLI ENTRYPOINT                                                              #\n",
        "###############################################################################\n",
        "if __name__ == \"__main__\":\n",
        "    build_snapshot_dataset()\n"
      ]
    }
  ]
}